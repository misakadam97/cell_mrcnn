{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "from cell_mrcnn.utils import get_weights_path_from_config_file, \\\n",
    "    get_data_path_from_config_file\n",
    "from matplotlib import pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import Mask RCNN\n",
    "from cell_mrcnn.config import Config\n",
    "from cell_mrcnn import model as modellib, utils\n",
    "\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = join(get_weights_path_from_config_file(), \"logs\")\n",
    "dataset_dir = join(get_data_path_from_config_file(), 'annotated_datasets')\n",
    "\n",
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "\n",
    "class CellConfig(Config):\n",
    "    \"\"\"Configuration for training on the 2 channel confocal dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"cell\"\n",
    "\n",
    "    IMAGE_CHANNEL_COUNT = 2\n",
    "    MEAN_PIXEL = np.array([4.5, 1.5])\n",
    "\n",
    "    # We use a GPU with 12GB memory, which can fit two images.\n",
    "    # Adjust down if you use a smaller GPU.\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + cell\n",
    "\n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 200\n",
    "    # todo: 0.98 might be too high\n",
    "    DETECTION_MIN_CONFIDENCE = 0.98\n",
    "\n",
    "    # Length of square anchor side in pixels\n",
    "    # Each scale is associated with a level of the pyramid\n",
    "    #todo: determine the appropriate anchor scales (basically u need to\n",
    "    # understand how the feaeture pyramide network and how the\n",
    "    # utils/generate_pyramid_anchors() work)\n",
    "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    # RPN proposals w/ an IoU  higher, than threshold get deleted, so lower\n",
    "    # threshold => more filtered.\n",
    "    # we don't want to detect overlapping cells (so you'd lower this)\n",
    "    RPN_NMS_THRESHOLD = 0.4\n",
    "\n",
    "    # to reduce memory load\n",
    "    BACKBONE = \"resnet18\"\n",
    "    DIV_FILTERNB = 2\n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 562\n",
    "    POST_NMS_ROIS_INFERENCE = 1024\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 128\n",
    "\n",
    "    # Random crops of size\n",
    "    IMAGE_RESIZE_MODE = \"crop\"\n",
    "    IMAGE_MIN_DIM = 1024\n",
    "    IMAGE_MAX_DIM = 1024\n",
    "\n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = True\n",
    "    # MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "\n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "\n",
    "    # Maximum number of ground truth instances to use in one image\n",
    "    MAX_GT_INSTANCES = 100\n",
    "\n",
    "    # Max number of final detections per image\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "\n",
    "    # Number of validation steps to run at the end of every training epoch.\n",
    "    # A bigger number improves accuracy of validation stats, but slows\n",
    "    # down the training.\n",
    "    VALIDATION_STEPS = 50\n",
    "\n",
    "\n",
    "class CellInferenceConfig(CellConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # Don't resize images for inferencing\n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Dataset\n",
    "############################################################\n",
    "\n",
    "\n",
    "class CellDataset(utils.Dataset):\n",
    "\n",
    "    def load_cell(self, path_to_dataset, subset):\n",
    "        \"\"\"Load the cell images.\n",
    "        path_to_dataset: Path to the dataset that contaions the annotated\n",
    "        images.\n",
    "        subset: Subset to load: train or val\n",
    "        \"\"\"\n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"cell\", 1, \"cell\")\n",
    "\n",
    "        # Train or validation dataset?\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        path_to_dataset = os.path.join(path_to_dataset, subset)\n",
    "\n",
    "        subfolders = [os.path.join(path_to_dataset, subfolder) for subfolder in\n",
    "                      os.listdir(path_to_dataset)]\n",
    "\n",
    "        for subfolder in subfolders:\n",
    "            image_names = [file_name for file_name in os.listdir(subfolder) if\n",
    "                           'mask' not in file_name]\n",
    "            # Add images\n",
    "            for image_name in image_names:\n",
    "                id = image_name.split('.')[0]\n",
    "                im_path = subfolder + '/' + image_name\n",
    "                self.add_image(\n",
    "                    \"cell\",\n",
    "                    image_id=id, # use file name as a unique image id\n",
    "                    path=im_path)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        # If not a cell dataset image, delegate to parent class.\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"cell\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        im_path = self.image_info[image_id]['path']\n",
    "        subfolder = '/'.join(im_path.split('/')[:-1]) + '/'\n",
    "        mask_names = [file_name for file_name in os.listdir(subfolder)\n",
    "                      if 'mask' in file_name]\n",
    "        mask = None\n",
    "        for mask_name in mask_names:\n",
    "            mask_path = subfolder + mask_name\n",
    "            mask_ = plt.imread(mask_path)\n",
    "            # add new dim so shape is (512,512,1) the 3rd dim is for different\n",
    "            # objects\n",
    "            mask_ = mask_[..., np.newaxis]\n",
    "            if mask is None:\n",
    "                mask = mask_\n",
    "            else:\n",
    "                mask = np.concatenate((mask, mask_), axis=2)\n",
    "\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"cell\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    dataset_path = join(dataset_dir, '2020_11_22_02_55_03/')\n",
    "    # Training dataset.\n",
    "    dataset_train = CellDataset()\n",
    "    dataset_train.load_cell(dataset_path, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = CellDataset()\n",
    "    dataset_val.load_cell(dataset_path, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # Image augmentation\n",
    "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
    "    augmentation = iaa.SomeOf((0, 2), [\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.OneOf([iaa.Affine(rotate=90),\n",
    "                   iaa.Affine(rotate=180),\n",
    "                   iaa.Affine(rotate=270)]),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 1.0)),\n",
    "        iaa.Add((-10, 10)),\n",
    "        iaa.Multiply((0.8, 1.5))\n",
    "    ])\n",
    "\n",
    "    print(\"Train all layers\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=35,\n",
    "                augmentation=augmentation,\n",
    "                layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CellConfig()\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=DEFAULT_LOGS_DIR)\n",
    "\n",
    "# load the last model trained\n",
    "weights_path = model.find_last()\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train all layers\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/miska/repos/cell_mrcnn/logs/cell20201018T1936/mask_rcnn_cell_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/50\n",
      "200/200 [==============================] - 209s 1s/step - loss: 2.4144 - rpn_class_loss: 0.1841 - rpn_bbox_loss: 0.8606 - mrcnn_class_loss: 0.2329 - mrcnn_bbox_loss: 0.5749 - mrcnn_mask_loss: 0.5619 - val_loss: 2.0466 - val_rpn_class_loss: 0.0883 - val_rpn_bbox_loss: 0.6297 - val_mrcnn_class_loss: 0.2187 - val_mrcnn_bbox_loss: 0.5213 - val_mrcnn_mask_loss: 0.5886\n",
      "WARNING:tensorflow:From /home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/50\n",
      " 54/200 [=======>......................] - ETA: 1:06 - loss: 2.2198 - rpn_class_loss: 0.1207 - rpn_bbox_loss: 0.6022 - mrcnn_class_loss: 0.3173 - mrcnn_bbox_loss: 0.5604 - mrcnn_mask_loss: 0.6191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/model.py\", line 1815, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/model.py\", line 1318, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-eb212ad49f8e>\", line 208, in load_mask\n",
      "    mask = np.concatenate((mask, mask_), axis=2)\n",
      "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "KeyboardInterrupt\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/model.py\", line 1815, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/model.py\", line 1318, in load_image_gt\n",
      "    mask, class_ids = dataset.load_mask(image_id)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/model.py\", line 1815, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "Process ForkPoolWorker-8:\n",
      "  File \"<ipython-input-5-eb212ad49f8e>\", line 208, in load_mask\n",
      "    mask = np.concatenate((mask, mask_), axis=2)\n",
      "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/model.py\", line 1326, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/utils/data_utils.py\", line 626, in next_sample\n",
      "    return six.next(_SHARED_SEQUENCES[uid])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/utils.py\", line 517, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/model.py\", line 1815, in data_generator\n",
      "    use_mini_mask=config.USE_MINI_MASK)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/scipy/ndimage/interpolation.py\", line 656, in zoom\n",
      "    _nd_image.zoom_shift(filtered, zoom, None, output, order, mode, cval)\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/model.py\", line 1326, in load_image_gt\n",
      "    mask = utils.resize_mask(mask, scale, padding, crop)\n",
      "  File \"/home/miska/repos/cell_mrcnn/src/cell_mrcnn/utils.py\", line 517, in resize_mask\n",
      "    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n",
      "  File \"/home/miska/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/scipy/ndimage/interpolation.py\", line 656, in zoom\n",
      "    _nd_image.zoom_shift(filtered, zoom, None, output, order, mode, cval)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9d3046b5d0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-eb212ad49f8e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                 layers='all')\n\u001b[0m",
      "\u001b[0;32m~/repos/cell_mrcnn/src/cell_mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2480\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2483\u001b[0m         )\n\u001b[1;32m   2484\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cell_mrcnn/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell_mrcnn",
   "language": "python",
   "name": "cell_mrcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
